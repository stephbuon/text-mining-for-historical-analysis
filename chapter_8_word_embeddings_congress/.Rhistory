tokens <- word_tokenizer(str_to_lower(data))
it <- itoken(tokens, ids = seq_along(tokens), progressbar = FALSE)
vocab <- create_vocabulary(it) %>%
prune_vocabulary(term_count_min = term_count_min)
vectorizer <- vocab_vectorizer(vocab)
tcm <- create_tcm(it, vectorizer, skip_grams_window = window)
set.seed(seed)
glove <- GlobalVectors$new(rank = rank, x_max = x_max)
wv_main <- glove$fit_transform(tcm, n_iter = n_iter)
wv_context <- glove$components
word_embeddings <- wv_main + t(wv_context) }
quiet_run <- function(expr) {
tf <- tempfile()
zz <- file(tf, open = "wt")
on.exit({
try(sink(type = "message"), silent = TRUE)
try(sink(), silent = TRUE)
close(zz)
unlink(tf) }, add = TRUE)
sink(zz)
sink(zz, type = "message")
force(expr) }
word_embeddings_2000 <- quiet_run(find_word_embeddings(climate_change_text_2000))
word_embeddings_2010 <- quiet_run(find_word_embeddings(climate_change_text_2010))
word_embeddings_2020 <- quiet_run(find_word_embeddings(climate_change_text_2020))
get_similar <- function(keyword, word_embeddings, top_n = top_n_default) {
kw_vec <- word_embeddings[keyword, , drop = FALSE]
cos_sim <- sim2(word_embeddings, kw_vec, method = "cosine", norm = "l2")[, 1]
tibble(word = names(cos_sim), similarity = unname(cos_sim)) %>%
filter(word != keyword) %>%
arrange(desc(similarity)) %>%
slice_head(n = top_n) }
most_similar_climate <- get_similar("climate", word_embeddings_2000, 10)
most_similar_emissions <- get_similar("emissions", word_embeddings_2000, 10)
most_similar_coal <- get_similar("coal", word_embeddings_2000, 20)
tbl_2000 <- most_similar_climate %>%
mutate(similarity = round(similarity, 3)) %>%
kable(
caption   = 'Words Most Related to "Climate": 2000s Congressional Records',
col.names = c("Word", "Cosine similarity"),
align     = c("l", "r"),
booktabs  = TRUE
) %>%
kable_styling(full_width = FALSE)
tbl_2000
knitr::opts_chunk$set(echo = TRUE)
source("https://raw.githubusercontent.com/Democracy-Lab/tmha.data/main/tools/install_tmha.data.R")
library(tmha.data)
library(text2vec)
library(tidyverse)
library(kableExtra)
data("congress_daily_climate_change_2000_2020")
congress_daily_climate_change_2000 <- congress_daily_climate_change_2000_2020 %>%
filter(decade == "2000")
climate_change_text_2000 <- congress_daily_climate_change_2000$content
congress_daily_climate_change_2010 <- congress_daily_climate_change_2000_2020 %>%
filter(decade == "2010")
climate_change_text_2010 <- congress_daily_climate_change_2000$content
congress_daily_climate_change_2020 <- congress_daily_climate_change_2000_2020 %>%
filter(decade == "2020")
climate_change_text_2020 <- congress_daily_climate_change_2020$content
find_word_embeddings <- function(data,
rank=50,
window=5L,
term_count_min=1,
x_max=10,
n_iter=30,
seed=42) {
tokens <- word_tokenizer(str_to_lower(data))
it <- itoken(tokens, ids = seq_along(tokens), progressbar = FALSE)
vocab <- create_vocabulary(it) %>%
prune_vocabulary(term_count_min = term_count_min)
vectorizer <- vocab_vectorizer(vocab)
tcm <- create_tcm(it, vectorizer, skip_grams_window = window)
set.seed(seed)
glove <- GlobalVectors$new(rank = rank, x_max = x_max)
wv_main <- glove$fit_transform(tcm, n_iter = n_iter)
wv_context <- glove$components
word_embeddings <- wv_main + t(wv_context) }
quiet_run <- function(expr) {
tf <- tempfile()
zz <- file(tf, open = "wt")
on.exit({
try(sink(type = "message"), silent = TRUE)
try(sink(), silent = TRUE)
close(zz)
unlink(tf) }, add = TRUE)
sink(zz)
sink(zz, type = "message")
force(expr) }
word_embeddings_2000 <- quiet_run(find_word_embeddings(climate_change_text_2000))
word_embeddings_2010 <- quiet_run(find_word_embeddings(climate_change_text_2010))
word_embeddings_2020 <- quiet_run(find_word_embeddings(climate_change_text_2020))
get_similar <- function(keyword, word_embeddings, top_n = top_n_default) {
kw_vec <- word_embeddings[keyword, , drop = FALSE]
cos_sim <- sim2(word_embeddings, kw_vec, method = "cosine", norm = "l2")[, 1]
tibble(word = names(cos_sim), similarity = unname(cos_sim)) %>%
filter(word != keyword) %>%
arrange(desc(similarity)) %>%
slice_head(n = top_n) }
most_similar_climate <- get_similar("climate", word_embeddings_2000, 10)
most_similar_emissions <- get_similar("emissions", word_embeddings_2000, 10)
most_similar_coal <- get_similar("coal", word_embeddings_2000, 20)
tbl_2000 <- most_similar_climate %>%
mutate(similarity = round(similarity, 3)) %>%
kable(
caption   = 'Words Most Related to "Climate": 2000s Congressional Records',
col.names = c("Word", "Cosine similarity"),
align     = c("l", "r"),
booktabs  = TRUE
) %>%
kable_styling(full_width = FALSE)
tbl_2000
tbl_2010 <- most_similar_2010 %>%
mutate(similarity = round(similarity, 3)) %>%
kable(
caption   = 'Words Most Related to "Climate": 2010s Congressional Records',
col.names = c("Word", "Cosine similarity"),
align     = c("l", "r"),
booktabs  = TRUE
) %>%
kable_styling(full_width = FALSE)
tbl_2010 <- most_similar_emissions %>%
mutate(similarity = round(similarity, 3)) %>%
kable(
caption   = 'Words Most Related to "Climate": 2010s Congressional Records',
col.names = c("Word", "Cosine similarity"),
align     = c("l", "r"),
booktabs  = TRUE
) %>%
kable_styling(full_width = FALSE)
tbl_2010
tbl_2020 <- most_similar_coal %>%
mutate(similarity = round(similarity, 3)) %>%
kable(
caption   = 'Words Most Related to "Coal": 2020s Congressional Records',
col.names = c("Word", "Cosine similarity"),
align     = c("l", "r"),
booktabs  = TRUE
) %>%
kable_styling(full_width = FALSE)
tbl_2020
library(tidyverse)
# take the top N words returned by most_similar_coal
words <- most_similar_coal$word
# include the anchor term too
words <- c("coal", words)
# subset embedding matrix to just those words
emb_small <- embeddings[words, ]
# take the top N words returned by most_similar_coal
words <- most_similar_coal$word
# include the anchor term too
words <- c("coal", words)
# subset embedding matrix to just those words
emb_small <- word_embeddings_2000[words, ]
# reduce high dimensions → 2D PCA
pca <- prcomp(emb_small, center = TRUE, scale. = TRUE)
coords <- as_tibble(pca$x[,1:2]) %>%
mutate(word = words)
# plot
ggplot(coords, aes(PC1, PC2, label = word)) +
geom_point(size = 3) +
geom_text(nudge_y = 0.04) +
theme_minimal() +
ggtitle("Words close to 'coal' in embedding space (2D PCA)")
# take the top N words returned by most_similar_coal
words <- word_embeddings_2000$word
word_embeddings_2000
# take the top N words returned by most_similar_coal
words <- most_similar_coal$word
# include the anchor term too
words <- c("coal", words)
# subset embedding matrix to just those words
emb_small <- word_embeddings_2000[words, ]
# reduce high dimensions → 2D PCA
pca <- prcomp(emb_small, center = TRUE, scale. = TRUE)
coords <- as_tibble(pca$x[,1:2]) %>%
mutate(word = words)
# plot
ggplot(coords, aes(PC1, PC2, label = word)) +
geom_point(size = 3) +
geom_text(nudge_y = 0.04) +
theme_minimal() +
ggtitle("Words close to 'coal' in embedding space (2D PCA)")
library(ggrepel)
# take the top N words returned by most_similar_coal
words <- most_similar_coal$word
# include the anchor term too
words <- c("coal", words)
# subset embedding matrix to just those words
emb_small <- word_embeddings_2000[words, ]
# reduce high dimensions → 2D PCA
pca <- prcomp(emb_small, center = TRUE, scale. = TRUE)
coords <- as_tibble(pca$x[,1:2]) %>%
mutate(word = words)
# plot
ggplot(coords, aes(PC1, PC2, label = word)) +
geom_point(size = 3) +
geom_text_repel() +
theme_minimal() +
ggtitle("Words close to 'coal' in embedding space (2D PCA)")
vector_subtraction <- function(word1, word2, embeddings, top_n = 10) {
# keep 1×d matrices so sim2() gets matrices on both sides
a <- embeddings[word1, , drop = FALSE]
b <- embeddings[word2, , drop = FALSE]
target <- a - b
sims <- sim2(embeddings, target, method = "cosine", norm = "l2")[, 1]
tibble(word = names(sims), similarity = unname(sims)) %>%
filter(!word %in% c(word1, word2)) %>%
arrange(desc(similarity)) %>%
slice_head(n = top_n) }
tbl_2000 <- most_similar_climate %>%
mutate(similarity = round(similarity, 3)) %>%
kable(caption = 'Words Most Related to "Climate": 2000s Congressional Records',
col.names = c("Word", "Cosine similarity"),
align = c("l", "r"),
booktabs = TRUE) %>%
kable_styling(full_width = FALSE)
tbl_2000
tbl_2020 <- most_similar_coal %>%
mutate(similarity = round(similarity, 3)) %>%
kable(caption = 'Words Most Related to "Coal": 2020s Congressional Records',
col.names = c("Word", "Cosine similarity"),
align = c("l", "r"),
booktabs = TRUE) %>%
kable_styling(full_width = FALSE)
tbl_2020
compare_two_words <- function(word_a, word_b) {
sims <- tibble(
decade = c("2000", "2010", "2020"),
similarity = c(
sim2(word_embeddings_2000[word_a,,drop=FALSE],
word_embeddings_2000[word_b,,drop=FALSE], method="cosine"),
sim2(word_embeddings_2010[word_a,,drop=FALSE],
word_embeddings_2010[word_b,,drop=FALSE], method="cosine"),
sim2(word_embeddings_2020[word_a,,drop=FALSE],
word_embeddings_2020[word_b,,drop=FALSE], method="cosine")
)[,1]
)
sims
}
# example comparing coal vs emissions (just an example pair)
df_sim <- compare_two_words("coal", "emissions")
library(text2vec)
library(tidyverse)
library(purrr)
# pass your decade embeddings here
embeddings_by_decade <- list(
"2000" = word_embeddings_2000,
"2010" = word_embeddings_2010,
"2020" = word_embeddings_2020
)
similarity_trajectory <- function(word_a, word_b, embs = embeddings_by_decade) {
sims <- tibble(
decade = names(embs)
) %>%
mutate(
similarity = map_dbl(decade, \(d) {
W <- embs[[d]]
# return NA if either word is OOV for this decade
if (!all(c(word_a, word_b) %in% rownames(W))) return(NA_real_)
as.numeric(sim2(
W[word_a, , drop = FALSE],
W[word_b, , drop = FALSE],
method = "cosine", norm = "l2"
))
})
)
sims
}
# example
df_sim <- similarity_trajectory("coal", "emissions")
ggplot(df_sim, aes(decade, similarity, group = 1)) +
geom_line(linewidth = 1) +
geom_point(size = 3) +
theme_minimal() +
labs(
title = "Cosine similarity across decades",
subtitle = "coal  ~  emissions",
x = "Decade", y = "Cosine similarity (−1 to 1)"
)
View(congress_daily_climate_change_2010)
library(tidyverse)
library(lubridate)
congress_daily_climate_change_enter <- congress_daily_climate_change_2000_2020 %>%
mutate(date = ymd(date),
year = year(date),
period_5 = paste0(floor(year/5)*5, "-", floor(year/5)*5 + 4))
library(tidyverse)
library(lubridate)
congress_daily_climate_change_enter <- congress_daily_climate_change_2000_2020 %>%
mutate(date = ymd(date),
year = year(date),
period_5 = paste0(floor(year/5)*5, "-", floor(year/5)*5 + 4))
congress_daily_climate_change_enter <- congress_daily_climate_change_enter %>%
mutate(period_5 = ifelseyear == 2020, "2020", period_5))
library(tidyverse)
library(lubridate)
congress_daily_climate_change_enter <- congress_daily_climate_change_2000_2020 %>%
mutate(date = ymd(date),
year = year(date),
period_5 = paste0(floor(year/5)*5, "-", floor(year/5)*5 + 4))
congress_daily_climate_change_enter <- congress_daily_climate_change_enter %>%
mutate(period_5 = ifelseyear == 2020, "2020", period_5)
library(tidyverse)
library(lubridate)
congress_daily_climate_change_enter <- congress_daily_climate_change_2000_2020 %>%
mutate(date = ymd(date),
year = year(date),
period_5 = paste0(floor(year/5)*5, "-", floor(year/5)*5 + 4))
congress_daily_climate_change_enter <- congress_daily_climate_change_enter %>%
mutate(period_5 = ifelse year == 2020, "2020", period_5)
library(tidyverse)
library(lubridate)
congress_daily_climate_change_enter <- congress_daily_climate_change_2000_2020 %>%
mutate(date = ymd(date),
year = year(date),
period_5 = paste0(floor(year/5)*5, "-", floor(year/5)*5 + 4))
congress_daily_climate_change_enter <- congress_daily_climate_change_enter %>%
mutate(period_5 = ifelse(year == 2020, "2020", period_5))
congress_daily_climate_change_enter
congress_daily_climate_change_enter
View(congress_daily_climate_change_enter)
library(text2vec)
library(tidyverse)
library(purrr)
library(tidyverse)
library(lubridate)
library(text2vec)
library(purrr)
# 0) Make 5-year periods (2000–2004, 2005–2009, 2010–2014, 2015–2019, 2020)
congress_5 <- congress_daily_climate_change_2000_2020 %>%
mutate(
date = ymd(date),
year = year(date),
period_5 = paste0(floor(year/5)*5, "-", floor(year/5)*5 + 4),
period_5 = ifelse(year == 2020, "2020", period_5)
)
# 1) Split text by 5-year period -> named list of character vectors
texts_by_period <- congress_5 %>%
filter(!is.na(content), str_squish(content) != "") %>%
split(.$period_5) %>%
map(~ .x$content)
# 2) Build embeddings per 5-year period
# Assumes you already have a function:
#   find_word_embeddings(text_vec) -> matrix with rownames = words
embeddings_by_period <- texts_by_period %>%
imap(~ {
if (length(.x) == 0) return(NULL)
find_word_embeddings(.x)
}) %>%
discard(is.null)
# 3) Similarity trajectory over 5-year periods
similarity_trajectory <- function(word_a, word_b, embs = embeddings_by_period) {
# order the x-axis by the numeric start year of each label
order_levels <- names(embs) %>%
as_tibble() %>%
rename(lbl = value) %>%
mutate(start = as.integer(str_replace(lbl, "-.*$", ""))) %>%
arrange(start) %>%
pull(lbl)
tibble(period = factor(names(embs), levels = order_levels)) %>%
mutate(
similarity = map_dbl(as.character(period), \(p) {
W <- embs[[p]]
if (is.null(W))                          return(NA_real_)
if (!all(c(word_a, word_b) %in% rownames(W))) return(NA_real_)
as.numeric(sim2(
W[word_a, , drop = FALSE],
W[word_b, , drop = FALSE],
method = "cosine", norm = "l2"
))
})
)
}
# 4) Example
df_sim <- similarity_trajectory("coal", "emissions")
ggplot(df_sim, aes(period, similarity, group = 1)) +
geom_line(linewidth = 1) +
geom_point(size = 3) +
theme_minimal() +
labs(
title = "Cosine similarity across 5-year periods",
subtitle = "coal  ~  emissions",
x = "5-year period", y = "Cosine similarity (−1 to 1)"
)
knitr::opts_chunk$set(echo = TRUE)
source("https://raw.githubusercontent.com/Democracy-Lab/tmha.data/main/tools/install_tmha.data.R")
library(tmha.data)
library(text2vec)
library(tidyverse)
library(kableExtra)
data("congress_daily_climate_change_2000_2020")
knitr::opts_chunk$set(echo = TRUE)
source("https://raw.githubusercontent.com/Democracy-Lab/tmha.data/main/tools/install_tmha.data.R")
library(tmha.data)
library(text2vec)
library(tidyverse)
library(kableExtra)
data("congress_daily_climate_change_2000_2020")
congress_daily_climate_change_2000 <- congress_daily_climate_change_2000_2020 %>%
filter(decade == "2000")
climate_change_text_2000 <- congress_daily_climate_change_2000$content
congress_daily_climate_change_2010 <- congress_daily_climate_change_2000_2020 %>%
filter(decade == "2010")
climate_change_text_2010 <- congress_daily_climate_change_2000$content
congress_daily_climate_change_2020 <- congress_daily_climate_change_2000_2020 %>%
filter(decade == "2020")
climate_change_text_2020 <- congress_daily_climate_change_2020$content
find_word_embeddings <- function(data,
rank=50,
window=5L,
term_count_min=1,
x_max=10,
n_iter=30,
seed=42) {
tokens <- word_tokenizer(str_to_lower(data))
it <- itoken(tokens, ids = seq_along(tokens), progressbar = FALSE)
vocab <- create_vocabulary(it) %>%
prune_vocabulary(term_count_min = term_count_min)
vectorizer <- vocab_vectorizer(vocab)
tcm <- create_tcm(it, vectorizer, skip_grams_window = window)
set.seed(seed)
glove <- GlobalVectors$new(rank = rank, x_max = x_max)
wv_main <- glove$fit_transform(tcm, n_iter = n_iter)
wv_context <- glove$components
word_embeddings <- wv_main + t(wv_context) }
quiet_run <- function(expr) {
tf <- tempfile()
zz <- file(tf, open = "wt")
on.exit({
try(sink(type = "message"), silent = TRUE)
try(sink(), silent = TRUE)
close(zz)
unlink(tf) }, add = TRUE)
sink(zz)
sink(zz, type = "message")
force(expr) }
word_embeddings_2000 <- quiet_run(find_word_embeddings(climate_change_text_2000))
word_embeddings_2010 <- quiet_run(find_word_embeddings(climate_change_text_2010))
word_embeddings_2020 <- quiet_run(find_word_embeddings(climate_change_text_2020))
get_similar <- function(keyword, word_embeddings, top_n = top_n_default) {
kw_vec <- word_embeddings[keyword, , drop = FALSE]
cos_sim <- sim2(word_embeddings, kw_vec, method = "cosine", norm = "l2")[, 1]
tibble(word = names(cos_sim), similarity = unname(cos_sim)) %>%
filter(word != keyword) %>%
arrange(desc(similarity)) %>%
slice_head(n = top_n) }
most_similar_climate <- get_similar("climate", word_embeddings_2000, 10)
most_similar_emissions <- get_similar("emissions", word_embeddings_2000, 10)
most_similar_coal <- get_similar("coal", word_embeddings_2000, 20)
tbl_2000 <- most_similar_climate %>%
mutate(similarity = round(similarity, 3)) %>%
kable(caption = 'Words Most Related to "Climate": 2000s Congressional Records',
col.names = c("Word", "Cosine similarity"),
align = c("l", "r"),
booktabs = TRUE) %>%
kable_styling(full_width = FALSE)
tbl_2000
tbl_2010 <- most_similar_emissions %>%
mutate(similarity = round(similarity, 3)) %>%
kable(caption = 'Words Most Related to "Emissions": 2010s Congressional Records',
col.names = c("Word", "Cosine similarity"),
align = c("l", "r"),
booktabs = TRUE) %>%
kable_styling(full_width = FALSE)
tbl_2010
tbl_2020 <- most_similar_coal %>%
mutate(similarity = round(similarity, 3)) %>%
kable(caption = 'Words Most Related to "Coal": 2020s Congressional Records',
col.names = c("Word", "Cosine similarity"),
align = c("l", "r"),
booktabs = TRUE) %>%
kable_styling(full_width = FALSE)
tbl_2020
library(ggrepel)
# take the top N words returned by most_similar_coal
words <- most_similar_coal$word
# include the anchor term too
words <- c("coal", words)
# subset embedding matrix to just those words
emb_small <- word_embeddings_2000[words, ]
# reduce high dimensions → 2D PCA
pca <- prcomp(emb_small, center = TRUE, scale. = TRUE)
coords <- as_tibble(pca$x[,1:2]) %>%
mutate(word = words)
# plot
ggplot(coords, aes(PC1, PC2, label = word)) +
geom_point(size = 3) +
geom_text_repel() +
theme_minimal() +
ggtitle("Words close to 'coal' in embedding space (2D PCA)")
vector_subtraction <- function(word1, word2, embeddings, top_n = 10) {
# keep 1×d matrices so sim2() gets matrices on both sides
a <- embeddings[word1, , drop = FALSE]
b <- embeddings[word2, , drop = FALSE]
target <- a - b
sims <- sim2(embeddings, target, method = "cosine", norm = "l2")[, 1]
tibble(word = names(sims), similarity = unname(sims)) %>%
filter(!word %in% c(word1, word2)) %>%
arrange(desc(similarity)) %>%
slice_head(n = top_n) }
vector_subtraction("climate", "science", congress_daily_climate_change_2000)
vector_subtraction("climate", "science", word_embeddings_2000)
vector_subtraction("democrat", "republican", word_embeddings_2000)
vector_subtraction("democrat", "republican", word_embeddings_2010)
vector_subtraction("earth", "pollution", word_embeddings_2000)
vector_subtraction("global", "local", word_embeddings_2000)
vector_subtraction("carbon", "methane", word_embeddings_2000)
vector_subtraction("renewables", "fossile", word_embeddings_2000)
vector_subtraction("renewable", "fossile", word_embeddings_2000)
vector_subtraction("renewable", "fossil", word_embeddings_2000)
