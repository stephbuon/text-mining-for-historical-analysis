ggplot(all_classes_count, aes(x = class, y = speakercount)) +
geom_col((aes(fill = class))) +
scale_fill_grey() +
geom_text(aes(label = paste0(speakercount, " speakers")),
colour = "white",
vjust = 1.5) +
labs(title = "How Many Speakers are in Each Category?", x = "", y = "speakers")
## Using Word Count:
## How much did speakers speak before and after the reform act?
# glue the data together for processing
all_per_speaker_wordcounts <- bind_rows(prereform_speakers_wordcount, postreform_speakers_wordcount) %>%
ungroup()
all_classes_unique <- all_classes %>%
distinct(suggested_speaker, .keep_all = TRUE)
all_speakers_annotated <- all_per_speaker_wordcounts %>%
left_join(all_classes_unique, by = "suggested_speaker") %>%
filter(!is.na(suggested_speaker)) %>%
ungroup()
# inspect the data
all_speakers_annotated
# find the total wordcount_per_speaker
wordcount_per_speaker <-  all_speakers_annotated %>%
rename(wordcount_per_speaker_per_year = wordcount) %>%
group_by(class, suggested_speaker) %>%
summarize(wordcount_per_speaker = sum(wordcount_per_speaker_per_year))
# find the most prolific n speakers of each period
top_speakers <- wordcount_per_speaker %>%
filter(!is.na(suggested_speaker)) %>%
group_by(class) %>%
arrange(desc(wordcount_per_speaker)) %>%
slice_head(n=5) %>%
mutate(top = TRUE)
#inspect the data
top_speakers
gc()
knitr::opts_chunk$set(echo = TRUE)
# load some data (hansardr version needed)
# dates 1822-1842
library("hansardr")
library("tidyverse")
library("lubridate")
data("hansard_1820")
data("hansard_1830")
data("hansard_1840")
data("debate_metadata_1820")
data("debate_metadata_1830")
data("debate_metadata_1840")
data("speaker_metadata_1820")
data("speaker_metadata_1830")
data("speaker_metadata_1840")
annotated_1820 <- hansard_1820 %>%
left_join(debate_metadata_1820)  %>%
mutate(year = year(speechdate)) %>%
left_join(speaker_metadata_1820) %>%
select(text, year, speechdate, suggested_speaker)
annotated_1830 <- hansard_1830 %>%
left_join(debate_metadata_1830) %>%
mutate(year = year(speechdate))  %>%
left_join(speaker_metadata_1830) %>%
select(text, year, speechdate, suggested_speaker)
annotated_1840 <- hansard_1840 %>%
left_join(debate_metadata_1840) %>%
mutate(year = year(speechdate))  %>%
left_join(speaker_metadata_1840) %>%
select(text, year, speechdate, suggested_speaker)
hansard <- bind_rows(annotated_1820, annotated_1830, annotated_1840)
# make two categories, pre- and post-reform
# find all the prereform text and speaker names
prereform <- hansard %>% #hansard_1830 %>%
#select(sentence_id, speechdate, debate, text, speaker, suggested_speaker) %>%
filter(speechdate <= as.Date("1832-6-4")) %>%
filter(speechdate >= as.Date("1822-6-4")) %>%
mutate(year = year(speechdate)) %>%
#  mutate(suggested_speaker = coalesce(suggested_speaker, speaker)) %>% # the "coalesce" function replaces a NA in the suggested_speaker column with whatever is in the speaker column
# filter(!is.na(speaker)) %>% ## a different count will result if we use this line as an alternative to the above
mutate(period = "prereform")
# find all the postreform text and speaker names
postreform <- hansard %>% #hansard_1830 %>%
# select(sentence_id, speechdate, debate, text, speaker, suggested_speaker) %>%
filter(speechdate >= as.Date("1832-6-4")) %>%
filter(speechdate <= as.Date("1842-6-4")) %>%
mutate(year = year(speechdate)) %>%
# mutate(suggested_speaker = coalesce(suggested_speaker, speaker)) %>% # the "coalesce" function replaces a NA in the suggested_speaker column with whatever is in the speaker column
#filter(!is.na(speaker)) %>% ## a different count will result if we use this line as an alternative to the above
mutate(period = "postreform")
rm(hansard, annotated_1820, annotated_1830, annotated_1840)
gc()
library("tidytext")
# tokenize words (this may be slow -- give it time)
prereform_words <- prereform %>%
unnest_tokens(word, text)
postreform_words <- postreform %>%
unnest_tokens(word, text)
# count the words
prereform_word_count <- prereform_words %>%
anti_join(stop_words) %>%
group_by(word) %>%
summarise(wordcount = n()) %>%
ungroup() %>%
arrange(desc(wordcount))  %>%
mutate(period = "prereform")
postreform_word_count <- postreform_words %>%
anti_join(stop_words) %>%
group_by(word) %>%
summarise(wordcount = n()) %>%
ungroup() %>%
arrange(desc(wordcount)) %>%
mutate(period = "postreform")
# glue the data together
both_periods_word_count <- bind_rows(prereform_word_count, postreform_word_count)
# tell the computer to put the periods in the correct order
both_periods_word_count$period <- factor(both_periods_word_count$period, levels = c("prereform", "postreform"))
# add up the total words for each period
both_periods_word_count_totals <- both_periods_word_count %>%
group_by(period) %>%
summarize(total = sum(wordcount))
# create a bar chart
library("scales") # a library useful for formatting numbers
ggplot(both_periods_word_count_totals, aes(x = period, y = total)) +
geom_col((aes(fill = period))) +
scale_fill_grey() +
scale_y_continuous(label=comma) +
geom_text(aes(label = (paste0(scales::comma(total), " words"))),
colour = "white",
vjust = 1.5) +
labs(title = "How Many Words Were Spoken in Each Period?", x = "", y = "words")
# subtract the prereform total wordcount from the postreform total word count to find the difference
print(both_periods_word_count_totals$total[2] - both_periods_word_count_totals$total[1])
library("gt")
# top words
top_words <- both_periods_word_count %>%
group_by(period) %>%
slice_max(order_by = wordcount, # put the words in descending order by "wordcount," the column for the count
n = 10) # the argument "n" for the function "slice_max" takes the number of positions from the top to retain
# make a table
top_words %>%
gt() %>% # we're using the "great tables" package to make an elegant table
fmt_number( # format the numbers in the table
columns = everything(), # apply to all numbers
decimals = 0, # no decimals
use_seps = TRUE # use commas
) %>%
tab_header(title = "The Top Ten Words Spoken in Prereform and Postreform Parliament") %>%
tab_style(
style = list(cell_text(weight = "bold")),
locations = cells_row_groups()
) %>%
tab_style( # format the column labels
style = list(
cell_fill(color = "black"),
cell_text(weight = "bold", color = "white")
),
locations = cells_column_labels()
) %>%
tab_style( # format the title
style = list(
cell_fill(color = "lightgray"),
cell_text(weight = "bold")
),
locations = cells_title()
)
# count words per speaker per year
prereform_speakers_wordcount <- prereform_words %>%
filter(suggested_speaker != "") %>%
group_by(suggested_speaker, year) %>%
summarize(wordcount = n()) %>%
ungroup() %>%
mutate(period = "prereform")
postreform_speakers_wordcount <- postreform_words %>%
filter(suggested_speaker != "") %>%
group_by(suggested_speaker, year) %>%
summarize(wordcount = n()) %>%
ungroup() %>%
mutate(period = "postreform")
# glue them together
both_periods_speakers <- rbind(prereform_speakers_wordcount, postreform_speakers_wordcount)
# inspect the data
head(both_periods_speakers)
rm(prereform_words, postreform_words)
# take the top speakers by wordcount
words_per_speaker <- both_periods_speakers %>%
group_by(suggested_speaker) %>%
summarize(wordsperspeaker = sum(wordcount))
top_speakers <- words_per_speaker %>%
slice_max(wordsperspeaker,
n = 5)
# inspect the data
top_speakers
# Use counting to investigate how many distinct speakers are in the data, pre and postreform
# How many speakers were there prereform?
prereform_only_speakers <- prereform_speakers_wordcount %>%
select(suggested_speaker) %>%
anti_join(postreform_speakers_wordcount, by = "suggested_speaker") %>%
mutate(class = "prereform only")
# inspect the data
prereform_only_speakers %>%
sample_n(10) %>%
head()
# count the number of speakers in the dataset
nrow(prereform_only_speakers)
# How many speakers were there postreform?
postreform_only_speakers <- postreform_speakers_wordcount %>%
select(suggested_speaker) %>%
anti_join(prereform_speakers_wordcount) %>%
mutate(class = "postreform only")
# inspect the data
head(postreform_only_speakers)
# count the number of speakers in the dataset
nrow(postreform_only_speakers)
nrow(postreform_only_speakers) - nrow(prereform_only_speakers)
# How Many Members of Parliament Spoke Both Prereform and Postreform?
continuous_speakers <- prereform_speakers_wordcount %>%
distinct(suggested_speaker) %>%
inner_join(postreform_speakers_wordcount) %>%
ungroup() %>%
mutate(class = "both periods") %>%
distinct(suggested_speaker, class)
nrow(continuous_speakers)
# Count the number of speakers in each category
# glue together the data from each smaller dataset
all_classes <- rbind(prereform_only_speakers, postreform_only_speakers, continuous_speakers)
# group by period and count the number of speakers
all_classes_count <- all_classes %>%
group_by(class) %>%
summarize(speakercount = n()) %>%
arrange(desc(class))
# tell the computer to put the periods in the correct order
all_classes_count$class <- factor(all_classes_count$class, levels = c("prereform only", "postreform only", "both periods"))
# create a bar chart
ggplot(all_classes_count, aes(x = class, y = speakercount)) +
geom_col((aes(fill = class))) +
scale_fill_grey() +
geom_text(aes(label = paste0(speakercount, " speakers")),
colour = "white",
vjust = 1.5) +
labs(title = "How Many Speakers are in Each Category?", x = "", y = "speakers")
## Using Word Count:
## How much did speakers speak before and after the reform act?
# glue the data together for processing
all_per_speaker_wordcounts <- bind_rows(prereform_speakers_wordcount, postreform_speakers_wordcount) %>%
ungroup()
all_classes_unique <- all_classes %>%
distinct(suggested_speaker, .keep_all = TRUE)
all_speakers_annotated <- all_per_speaker_wordcounts %>%
left_join(all_classes_unique, by = "suggested_speaker") %>%
filter(!is.na(suggested_speaker)) %>%
ungroup()
# inspect the data
all_speakers_annotated
# find the total wordcount_per_speaker
wordcount_per_speaker <-  all_speakers_annotated %>%
rename(wordcount_per_speaker_per_year = wordcount) %>%
group_by(class, suggested_speaker) %>%
summarize(wordcount_per_speaker = sum(wordcount_per_speaker_per_year))
# find the most prolific n speakers of each period
top_speakers <- wordcount_per_speaker %>%
filter(!is.na(suggested_speaker)) %>%
group_by(class) %>%
arrange(desc(wordcount_per_speaker)) %>%
slice_head(n=5) %>%
mutate(top = TRUE)
#inspect the data
top_speakers
# clean up speaker names
annotated_1820 <- hansard_1820 %>%
left_join(debate_metadata_1820)  %>%
mutate(year = year(speechdate)) %>%
left_join(speaker_metadata_1820) %>%
select(text, year, speechdate, suggested_speaker)
annotated_1830 <- hansard_1830 %>%
left_join(debate_metadata_1830) %>%
mutate(year = year(speechdate))  %>%
left_join(speaker_metadata_1830) %>%
select(text, year, speechdate, suggested_speaker)
annotated_1840 <- hansard_1840 %>%
left_join(debate_metadata_1840) %>%
mutate(year = year(speechdate))  %>%
left_join(speaker_metadata_1840) %>%
select(text, year, speechdate, suggested_speaker)
hansard <- bind_rows(annotated_1820, annotated_1830, annotated_1840)
speaker_key <- hansard %>%
select(suggested_speaker) %>%
group_by(suggested_speaker) %>%
sample_n(1)
# inspect the data
speaker_key %>%
filter(str_detect(suggested_speaker, "peel_"))
speakers_w_top_and_speaker_key <- all_speakers_annotated %>%
rename(wordcount_per_speaker_per_year = wordcount) %>%
left_join(top_speakers, by = c("suggested_speaker", "class")) %>%
#left_join(speaker_key) #%>%
#distinct()
#*********** STEPH this process generates multiple entires, which is why i resort to distinct(). do you have a more elegant solution? thanks! JG
#inspect the data
speakers_w_top_and_speaker_key %>%
filter(str_detect(suggested_speaker, "peel_")) %>%
select(suggested_speaker, top, year, wordcount_per_speaker_per_year, class) %>%
head() %>%
kable()
library(kable)
library(kableExtra)
speakers_w_top_and_speaker_key <- all_speakers_annotated %>%
rename(wordcount_per_speaker_per_year = wordcount) %>%
left_join(top_speakers, by = c("suggested_speaker", "class")) %>%
#left_join(speaker_key) #%>%
#distinct()
#*********** STEPH this process generates multiple entires, which is why i resort to distinct(). do you have a more elegant solution? thanks! JG
#inspect the data
speakers_w_top_and_speaker_key %>%
filter(str_detect(suggested_speaker, "peel_")) %>%
select(suggested_speaker, top, year, wordcount_per_speaker_per_year, class) %>%
head() %>%
kable()
speakers_w_top_and_speaker_key <- all_speakers_annotated %>%
rename(wordcount_per_speaker_per_year = wordcount) %>%
left_join(top_speakers, by = c("suggested_speaker", "class")) %>%
#left_join(speaker_key) #%>%
#distinct()
#*********** STEPH this process generates multiple entires, which is why i resort to distinct(). do you have a more elegant solution? thanks! JG
#inspect the data
speakers_w_top_and_speaker_key %>%
filter(str_detect(suggested_speaker, "peel_")) %>%
select(suggested_speaker, top, year, wordcount_per_speaker_per_year, class) %>%
head() %>%
kable()
speakers_w_top_and_speaker_key <- all_speakers_annotated %>%
rename(wordcount_per_speaker_per_year = wordcount) %>%
left_join(top_speakers, by = c("suggested_speaker", "class")) %>%
#left_join(speaker_key) #%>%
#distinct()
#*********** STEPH this process generates multiple entires, which is why i resort to distinct(). do you have a more elegant solution? thanks! JG
#inspect the data
speakers_w_top_and_speaker_key %>%
filter(str_detect(suggested_speaker, "peel_")) %>%
select(suggested_speaker, top, year, wordcount_per_speaker_per_year, class) %>%
head() %>%
kable()
speakers_w_top_and_speaker_key <- all_speakers_annotated %>%
rename(wordcount_per_speaker_per_year = wordcount) %>%
left_join(top_speakers, by = c("suggested_speaker", "class")) %>%
left_join(speaker_key) #%>%
#distinct()
speakers_w_top_and_speaker_key <- all_speakers_annotated %>%
rename(wordcount_per_speaker_per_year = wordcount) %>%
left_join(top_speakers, by = c("suggested_speaker", "class")) %>%
left_join(speaker_key)
speakers_w_top_and_speaker_key %>%
filter(str_detect(suggested_speaker, "peel_")) %>%
select(suggested_speaker, top, year, wordcount_per_speaker_per_year, class) %>%
head() %>%
kable()
# graph it
library("ggrepel") # load a useful package for labeling a dense plot
ggplot(speakers_w_top_and_speaker_key, aes(x = year, y = wordcount_per_speaker_per_year, color = class, shape = class)) +
geom_jitter( # it's worth replacing the geom_jitter with geom_point here and in the next line to see the stakes of diff representations
size = 3
) +
scale_color_grey(guide = guide_legend()) +
geom_label_repel(data=subset(speakers_w_top_and_speaker_key, top == TRUE),
aes(label=suggested_speaker, color = class)) +
guides(fill = "none", label = "none", size = "none") +
theme(legend.position="bottom") +
labs(title = "How Much Did Speakers Speak",
subtitle = "Before and After the Second Reform Act of 1832?")
prereform_top_words_w_speaker_classifications_tfidf <- prereform_words_w_speaker_classifications_tfidf %>%
filter(!is.na(tf_idf)) %>%  # remove NA scores
group_by(class) %>%
arrange(desc(tf_idf)) %>%
slice_head(n =15) %>%
mutate(word = reorder_within(word, wordsperperiod, class))
prereform_words_w_speaker_classifications_tfidf <- prereform_words_w_speaker_classifications_counted %>%
bind_tf_idf(word, class, wordsperperiod) %>%
filter(!is.na(class), !is.na(tf_idf)) %>%     # remove NAs before plotting
select(word, class, wordsperperiod, tf_idf)
View(prereform_speakers_wordcount)
View(postreform_speakers_wordcount)
prereform_words_w_speaker_classifications <- prereform_speeches %>%
filter(year >= 1822, year <= 1832) %>%
unnest_tokens(word, text) %>%
anti_join(stop_words, by = "word") %>%
filter(!str_detect(word, "^[0-9]+$")) %>%   # drop pure numbers
count(class, word, name = "wordsperperiod")
prereform_words_w_speaker_classifications_tfidf <-
prereform_words_w_speaker_classifications %>%
# make sure there is one row per class–word pair with a count
group_by(class, word) %>%
summarise(wordsperperiod = sum(wordsperperiod), .groups = "drop") %>%
# compute tf, idf, and tf-idf
bind_tf_idf(
term     = word,          # the word column
document = class,         # “document” = class (or whatever grouping you want)
n        = wordsperperiod # count column
)
prereform_words_w_speaker_classifications_tfidf <-
prereform_speakers_wordcount %>%
# rename to expected variable names
rename(wordsperperiod = wordcount) %>%
# create a word column (tokenize or if you already have one, remove this step)
unnest_tokens(word, suggested_speaker) %>%
# group for tf-idf structure
group_by(class, word) %>%
summarise(wordsperperiod = sum(wordsperperiod), .groups = "drop") %>%
# compute tf-idf
bind_tf_idf(
term     = word,
document = class,
n        = wordsperperiod
)
prereform_words_w_speaker_classifications_tfidf <- prereform_words_w_speaker_classifications_counted %>%
bind_tf_idf(word, class, wordsperperiod) %>%
filter(!is.na(class), !is.na(tf_idf)) %>%     # remove NAs before plotting
select(word, class, wordsperperiod, tf_idf)
# Use Basic Counting and a Histogram to Investigate How Many Speakers Spoke at the Maximum and Minimum Amounts
# Part 1: Prereform
prereform_only_speakers_wordcount <- prereform_speakers_wordcount %>%
inner_join(prereform_only_speakers)
hist(prereform_only_speakers_wordcount$wordcount)
ggplot(prereform_only_speakers_wordcount, aes(x = wordcount)) +
#geom_dotplot(binwidth=1000)# +
geom_histogram(binwidth = 1000) +
labs(title = "How many prereform speakers spoke how many words?", x = "words spoken", y= "number of speakers")
# Use Basic Counting and a Histogram to Investigate How Many Speakers Spoke at the Maximum and Minimum Amounts
# Part 2: Postreform
postreform_only_speakers_wordcount <- postreform_speakers_wordcount %>%
inner_join(postreform_only_speakers)
hist(postreform_only_speakers_wordcount$wordcount)
ggplot(postreform_only_speakers_wordcount, aes(x = wordcount)) +
#geom_dotplot(binwidth=1000)# +
geom_histogram(binwidth = 1000) +
labs(title = "How many postreform speakers spoke how many words?", x = "words spoken", y= "number of speakers")
# Applying Tf-idf with a Different Data Architecture Part 3:
# For comparing postreform and prereform speech, does it matter whether we only look at the speakers who spoke a lot?
library("textstem")
major_prereform_speakers <- prereform_only_speakers_wordcount %>%
filter(wordcount >= 10000) # <--- here is the cutoff. Change it and see if the results differ!
major_postreform_speakers <- postreform_only_speakers_wordcount %>%
filter(wordcount >= 10000)
major_speakers <- rbind(major_prereform_speakers, major_postreform_speakers)
top_words_w_speaker_classifications_tfidf <- words_w_speaker_classifications %>%
filter(suggested_speaker %in% major_speakers$suggested_speaker) %>%
group_by(class, word) %>%
summarize(wordsperperiod = n()) %>%
bind_tf_idf(word, class, wordsperperiod) %>%
select(word, class, wordsperperiod, tf_idf) %>%
group_by(class) %>%
arrange(desc(tf_idf)) %>%
slice_head(n = 15) %>%
mutate(word = reorder_within(word, wordsperperiod, class))
# Applying Tf-idf with a Different Data Architecture Part 4:
# Who were the most distinctive prereform/postreform speakers and their words?
words_w_speaker_classifications_tfidf <- words_w_speaker_classifications %>%
filter(suggested_speaker %in% major_speakers$suggested_speaker) %>%
group_by(class, suggested_speaker, word) %>%
summarize(wordsperspeaker = n()) %>%
bind_tf_idf(word, suggested_speaker, wordsperspeaker) %>%
ungroup() %>%
select(word, suggested_speaker, class, wordsperspeaker, tf_idf)
data("hansard_1850")
data("hansard_1860")
data("hansard_1870")
data("debate_metadata_1850")
data("debate_metadata_1860")
data("debate_metadata_1870")
data("speaker_metadata_1850")
data("speaker_metadata_1860")
data("speaker_metadata_1870")
annotated_1850 <- hansard_1850 %>%
left_join(debate_metadata_1850)  %>%
mutate(year = year(speechdate)) %>%
left_join(speaker_metadata_1850) %>%
select(text, year, suggested_speaker)
annotated_1860 <- hansard_1860 %>%
left_join(debate_metadata_1860) %>%
mutate(year = year(speechdate))  %>%
left_join(speaker_metadata_1860)# %>%
select(text, year, suggested_speaker)
data("hansard_1850")
data("hansard_1860")
data("hansard_1870")
data("debate_metadata_1850")
data("debate_metadata_1860")
data("debate_metadata_1870")
data("speaker_metadata_1850")
data("speaker_metadata_1860")
data("speaker_metadata_1870")
annotated_1850 <- hansard_1850 %>%
left_join(debate_metadata_1850)  %>%
mutate(year = year(speechdate)) %>%
left_join(speaker_metadata_1850) %>%
select(text, year, suggested_speaker)
annotated_1860 <- hansard_1860 %>%
left_join(debate_metadata_1860) %>%
mutate(year = year(speechdate))  %>%
left_join(speaker_metadata_1860) %>%
select(text, year, suggested_speaker)
annotated_1870 <- hansard_1870 %>%
left_join(debate_metadata_1870) %>%
mutate(year = year(speechdate))  %>%
left_join(speaker_metadata_1870) %>%
select(text, year, suggested_speaker)
hansard <- bind_rows(annotated_1870, annotated_1870) %>%
bind_rows(annotated_1870)
# make two categories, pre- and post-reform
prereform <- hansard %>% #hansard_1830 %>%
select(sentence_id, speechdate, debate, text, speaker, suggested_speaker) %>%
#bind_rows(hansard_1820) %>%
filter(speechdate <= as.Date("1869-1-1")) %>%
filter(speechdate >= as.Date("1859-1-1")) %>%
mutate(year = year(speechdate)) %>%
mutate(suggested_speaker = coalesce(suggested_speaker, speaker)) %>% # the "coalesce" function replaces a NA in the suggested_speaker column with whatever is in the speaker column
# filter(!is.na(speaker)) %>% ## a different count will result if we use this line as an alternative to the above
mutate(period = "prereform")
